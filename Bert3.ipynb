{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a527d5f-6c6f-4cf5-a409-eebc093c5248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "from datasets import load_dataset,concatenate_datasets, load_metric\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd48b64-b6f4-4f9a-a9eb-bbd20631bbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a8b6c939ec46e690be3472754604f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed36aa5e56a40bc878d7fe270c4910d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/4.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52bcddc05d6432ab6bd5731cc6dd222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wnut_17/wnut_17 to C:/Users/Serdar Arslan/.cache/huggingface/datasets/wnut_17/wnut_17/1.0.0/077c7f08b8dbc800692e8c9186cdf3606d5849ab0e7be662e6135bb10eba54f9...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874312b54c3d4e9c825c624115322d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9539320f43ef4044ba89fbc1a74286c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41cacf9983684b3f835d5ef4326c9351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/39.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5776304839f4dafb27ce1f6026b1ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/66.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34033bdb26743ec8eefb35d7224610d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4d9884daba460b8bc8ba7101b228c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1009 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wnut_17 downloaded and prepared to C:/Users/Serdar Arslan/.cache/huggingface/datasets/wnut_17/wnut_17/1.0.0/077c7f08b8dbc800692e8c9186cdf3606d5849ab0e7be662e6135bb10eba54f9. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd88e0d9c0f491c9efd598881b6f0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 3394\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1009\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1287\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnut = load_dataset(\"wnut_17\")\n",
    "wnut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590c6abc-4c7e-474d-99fe-60c5cec4ab4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-corporation',\n",
       " 2: 'I-corporation',\n",
       " 3: 'B-creative-work',\n",
       " 4: 'I-creative-work',\n",
       " 5: 'B-group',\n",
       " 6: 'I-group',\n",
       " 7: 'B-location',\n",
       " 8: 'I-location',\n",
       " 9: 'B-person',\n",
       " 10: 'I-person',\n",
       " 11: 'B-product',\n",
       " 12: 'I-product'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = wnut[\"train\"].features[f\"ner_tags\"].feature.names\n",
    "id2tag = {id: tag for id, tag in enumerate(label_list)}\n",
    "id2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc81495-810f-4c69-a09d-8e075e04fc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'ner_tags'],\n",
       "    num_rows: 4403\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge train & validation sets\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "train_dataset = concatenate_datasets([wnut[\"train\"],wnut[\"validation\"]])\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62990bf1-8a4b-48ee-b015-9b6e3437ab48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pxleyes', 'Top', '50', 'Photography', 'Contest', 'Pictures', 'of', 'August', '2010', '...', 'http://bit.ly/bgCyZ0', '#photography']\n",
      "['B-corporation', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "ith_example=2\n",
    "\n",
    "print(wnut[\"train\"][ith_example]['tokens'])\n",
    "print([id2tag[label] for label in train_dataset[ith_example]['ner_tags']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8b40c9-8421-4a89-b3d3-9828fed40d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a27e743e8144e99f8ca6efd4d07d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffad4a0c42d34c31bba795091b2ed82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847a2f2cb083472c867338d8785c23e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842c740130744e6e9c0bc312c62b2ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6504e6b-d9c0-47ae-8777-42c96bbde4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yeti', 'rescue', 'ad000092', ',', 'size50', '(', 'parts', 'for', 'paraglider', ')']\n",
      "{'input_ids': [101, 2664, 2072, 5343, 4748, 8889, 8889, 2683, 2475, 1010, 2946, 12376, 1006, 3033, 2005, 11498, 25394, 4063, 1007, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Tokens:----------------------------\n",
      "['[CLS]', 'yet', '##i', 'rescue', 'ad', '##00', '##00', '##9', '##2', ',', 'size', '##50', '(', 'parts', 'for', 'para', '##gli', '##der', ')', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "#buraya bizim veri setlerini tokenize edip eklememiz lazım\n",
    "token_str = list(map(str.lower, ['YETI', 'RESCUE', 'AD000092', ',', 'SIZE50', '(', 'PARTS', 'FOR', 'PARAGLIDER', ')']))\n",
    "\n",
    "print(token_str)\n",
    "tokenized_input = tokenizer(token_str, is_split_into_words=True)\n",
    "print(tokenized_input)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(\"Tokens:----------------------------\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30b7452a-ada9-471f-9c01-0a2575a7b1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'p', '##xley', '##es', 'top', '50', 'photography', 'contest', 'pictures', 'of', 'august', '2010', '.', '.', '.', 'http', ':', '/', '/', 'bit', '.', 'l', '##y', '/', 'b', '##gc', '##y', '##z', '##0', '#', 'photography', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(wnut[\"train\"][2][\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "#tokenized\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01800d0a-a2bd-4042-8e3b-9205de059c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(AIR COMBAT SIMULATOR PARTS) DIGITAL OUTPUT 32...</td>\n",
       "      <td>['(', 'AIR', 'COMBAT', 'SIMULATOR', 'PARTS', '...</td>\n",
       "      <td>['O ', 'B_PRODUCT', 'I_PRODUCT', 'I_PRODUCT', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(AIR COMBAT SIMULATOR PARTS)AMPLIFIER-4-CHANNE...</td>\n",
       "      <td>['(', 'AIR', 'COMBAT', 'SIMULATOR', 'PARTS', '...</td>\n",
       "      <td>['O ', 'B_PRODUCT', 'I_PRODUCT', 'I_PRODUCT', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(AIR COMBAT SIMULATOR PARTS)AMPLIFIER-4-CHANNE...</td>\n",
       "      <td>['(', 'AIR', 'COMBAT', 'SIMULATOR', 'PARTS', '...</td>\n",
       "      <td>['O ', 'B_PRODUCT', 'I_PRODUCT', 'I_PRODUCT', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(AIR COMBAT SIMULATOR PARTS)AMPLIFIER-4-CHANNE...</td>\n",
       "      <td>['(', 'AIR', 'COMBAT', 'SIMULATOR', 'PARTS', '...</td>\n",
       "      <td>['O ', 'B_PRODUCT', 'I_PRODUCT', 'I_PRODUCT', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(AIR COMBAT SIMULATOR PARTS)AMPLIFIER-4-CHANNE...</td>\n",
       "      <td>['(', 'AIR', 'COMBAT', 'SIMULATOR', 'PARTS', '...</td>\n",
       "      <td>['O ', 'B_PRODUCT', 'I_PRODUCT', 'I_PRODUCT', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(AIR COMBAT SIMULATOR PARTS)TOGGLE SWITCH PNO-...</td>\n",
       "      <td>['(', 'AIR', 'COMBAT', 'SIMULATOR', 'PARTS', '...</td>\n",
       "      <td>['O ', 'B_PRODUCT', 'I_PRODUCT', 'I_PRODUCT', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>(FOC SHIPMENT)LEADING EDGE GUARD (697039655) (...</td>\n",
       "      <td>['(', 'FOC', 'SHIPMENT', ')', 'LEADING', 'EDGE...</td>\n",
       "      <td>['O ', 'O ', 'O ', 'O ', 'B_PRODUCT', 'I_PRODU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>(FOC) (P/N:233A5512-3) SEAT GUARD ASSY</td>\n",
       "      <td>['(', 'FOC', ')', '(', 'P', '/', 'N', ':', '23...</td>\n",
       "      <td>['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>(FOC) (P/N:53727-22) ROD ASSY, FOLDED</td>\n",
       "      <td>['(', 'FOC', ')', '(', 'P', '/', 'N', ':', '53...</td>\n",
       "      <td>['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>(FOC) (P/N:53727-25) STRUT AY</td>\n",
       "      <td>['(', 'FOC', ')', '(', 'P', '/', 'N', ':', '53...</td>\n",
       "      <td>['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            product  \\\n",
       "0   0  (AIR COMBAT SIMULATOR PARTS) DIGITAL OUTPUT 32...   \n",
       "1   1  (AIR COMBAT SIMULATOR PARTS)AMPLIFIER-4-CHANNE...   \n",
       "2   2  (AIR COMBAT SIMULATOR PARTS)AMPLIFIER-4-CHANNE...   \n",
       "3   3  (AIR COMBAT SIMULATOR PARTS)AMPLIFIER-4-CHANNE...   \n",
       "4   4  (AIR COMBAT SIMULATOR PARTS)AMPLIFIER-4-CHANNE...   \n",
       "5   5  (AIR COMBAT SIMULATOR PARTS)TOGGLE SWITCH PNO-...   \n",
       "6   6  (FOC SHIPMENT)LEADING EDGE GUARD (697039655) (...   \n",
       "7   7            (FOC) (P/N:233A5512-3) SEAT GUARD ASSY    \n",
       "8   8             (FOC) (P/N:53727-22) ROD ASSY, FOLDED    \n",
       "9   9                     (FOC) (P/N:53727-25) STRUT AY    \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['(', 'AIR', 'COMBAT', 'SIMULATOR', 'PARTS', '...   \n",
       "1  ['(', 'AIR', 'COMBAT', 'SIMULATOR', 'PARTS', '...   \n",
       "2  ['(', 'AIR', 'COMBAT', 'SIMULATOR', 'PARTS', '...   \n",
       "3  ['(', 'AIR', 'COMBAT', 'SIMULATOR', 'PARTS', '...   \n",
       "4  ['(', 'AIR', 'COMBAT', 'SIMULATOR', 'PARTS', '...   \n",
       "5  ['(', 'AIR', 'COMBAT', 'SIMULATOR', 'PARTS', '...   \n",
       "6  ['(', 'FOC', 'SHIPMENT', ')', 'LEADING', 'EDGE...   \n",
       "7  ['(', 'FOC', ')', '(', 'P', '/', 'N', ':', '23...   \n",
       "8  ['(', 'FOC', ')', '(', 'P', '/', 'N', ':', '53...   \n",
       "9  ['(', 'FOC', ')', '(', 'P', '/', 'N', ':', '53...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0  ['O ', 'B_PRODUCT', 'I_PRODUCT', 'I_PRODUCT', ...  \n",
       "1  ['O ', 'B_PRODUCT', 'I_PRODUCT', 'I_PRODUCT', ...  \n",
       "2  ['O ', 'B_PRODUCT', 'I_PRODUCT', 'I_PRODUCT', ...  \n",
       "3  ['O ', 'B_PRODUCT', 'I_PRODUCT', 'I_PRODUCT', ...  \n",
       "4  ['O ', 'B_PRODUCT', 'I_PRODUCT', 'I_PRODUCT', ...  \n",
       "5  ['O ', 'B_PRODUCT', 'I_PRODUCT', 'I_PRODUCT', ...  \n",
       "6  ['O ', 'O ', 'O ', 'O ', 'B_PRODUCT', 'I_PRODU...  \n",
       "7  ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ...  \n",
       "8  ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ...  \n",
       "9  ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bizim data\n",
    "df = pd.read_excel('data/test.xlsx', sheet_name='sheet1')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b7716fa-1b34-4603-81bb-4447ff0e424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c5fe293e99e203b5\n",
      "Reusing dataset csv (C:\\Users\\pc\\.cache\\huggingface\\datasets\\csv\\default-c5fe293e99e203b5\\0.0.0\\652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1034.35it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f167628b-19ae-42fd-b0f1-5c0f6384dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c883c66-171a-4b52-989a-c069da88f141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a645cf76485824ff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/Serdar Arslan/.cache/huggingface/datasets/csv/default-a645cf76485824ff/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ffef497a324dbfbadb6045c090ad12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291a2961d5784229ab75ab13c48ab469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/Serdar Arslan/.cache/huggingface/datasets/csv/default-a645cf76485824ff/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2db835dea646f29f08a3e2820beee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 3243\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"csv\", data_files=\"data/test2.csv\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6392d010-f411-4f54-8753-7183451e9b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd2ffe6a1e14f17a25e5ffa636ade53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3a22075ad232>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtokenized_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize_and_align_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\datasets\\dataset_dict.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    775\u001b[0m             \u001b[0mcache_file_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m         return DatasetDict(\n\u001b[1;32m--> 777\u001b[1;33m             {\n\u001b[0m\u001b[0;32m    778\u001b[0m                 k: dataset.map(\n\u001b[0;32m    779\u001b[0m                     \u001b[0mfunction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\datasets\\dataset_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    776\u001b[0m         return DatasetDict(\n\u001b[0;32m    777\u001b[0m             {\n\u001b[1;32m--> 778\u001b[1;33m                 k: dataset.map(\n\u001b[0m\u001b[0;32m    779\u001b[0m                     \u001b[0mfunction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m                     \u001b[0mwith_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwith_indices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   2583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2585\u001b[1;33m             return self._map_single(\n\u001b[0m\u001b[0;32m   2586\u001b[0m                 \u001b[0mfunction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2587\u001b[0m                 \u001b[0mwith_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwith_indices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Dataset\"\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"self\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;31m# apply actual function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DatasetDict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m         }\n\u001b[0;32m    551\u001b[0m         \u001b[1;31m# apply actual function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DatasetDict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;31m# re-apply format to the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\datasets\\fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m             \u001b[1;31m# Call actual function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m             \u001b[1;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[0;32m   2980\u001b[0m                         )  # Something simpler?\n\u001b[0;32m   2981\u001b[0m                         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2982\u001b[1;33m                             batch = apply_function_on_filtered_inputs(\n\u001b[0m\u001b[0;32m   2983\u001b[0m                                 \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2984\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[1;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   2863\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2864\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2865\u001b[1;33m             \u001b[0mprocessed_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2866\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2867\u001b[0m                 \u001b[1;31m# Check if the function returns updated examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(item, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2543\u001b[0m                 )\n\u001b[0;32m   2544\u001b[0m                 \u001b[1;31m# Use the LazyDict internally, while mapping the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2545\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecorated_item\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2546\u001b[0m                 \u001b[1;31m# Return a standard dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2547\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-5ba3e288ed59>\u001b[0m in \u001b[0;36mtokenize_and_align_labels\u001b[1;34m(examples)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"ner_tags\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mword_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenized_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Map tokens to their respective word.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mprevious_word_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mlabel_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mword_ids\u001b[1;34m(self, batch_index)\u001b[0m\n\u001b[0;32m    364\u001b[0m                 \u001b[1;34m\" class).\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m             )\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encodings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoken_to_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_or_token_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tokenized_df = ds.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4efb7c2c-9b76-47a1-9265-c053a41d4833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  7.64ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 25.84ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 17.75ba/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 13.61ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_wnut = wnut.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c36975d-2dca-423e-b9f8-b7e57f46607b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['@paulwalk',\n",
       "  'It',\n",
       "  \"'s\",\n",
       "  'the',\n",
       "  'view',\n",
       "  'from',\n",
       "  'where',\n",
       "  'I',\n",
       "  \"'m\",\n",
       "  'living',\n",
       "  'for',\n",
       "  'two',\n",
       "  'weeks',\n",
       "  '.',\n",
       "  'Empire',\n",
       "  'State',\n",
       "  'Building',\n",
       "  '=',\n",
       "  'ESB',\n",
       "  '.',\n",
       "  'Pretty',\n",
       "  'bad',\n",
       "  'storm',\n",
       "  'here',\n",
       "  'last',\n",
       "  'evening',\n",
       "  '.'],\n",
       " 'ner_tags': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  0,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'input_ids': [101,\n",
       "  1030,\n",
       "  2703,\n",
       "  17122,\n",
       "  2009,\n",
       "  1005,\n",
       "  1055,\n",
       "  1996,\n",
       "  3193,\n",
       "  2013,\n",
       "  2073,\n",
       "  1045,\n",
       "  1005,\n",
       "  1049,\n",
       "  2542,\n",
       "  2005,\n",
       "  2048,\n",
       "  3134,\n",
       "  1012,\n",
       "  3400,\n",
       "  2110,\n",
       "  2311,\n",
       "  1027,\n",
       "  9686,\n",
       "  2497,\n",
       "  1012,\n",
       "  3492,\n",
       "  2919,\n",
       "  4040,\n",
       "  2182,\n",
       "  2197,\n",
       "  3944,\n",
       "  1012,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [-100,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  0,\n",
       "  7,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bff88bcd-6fdf-476d-b01c-2a75f756725f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_labels</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p</td>\n",
       "      <td>1</td>\n",
       "      <td>B-corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>##xley</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##es</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>top</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>photography</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>contest</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pictures</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>of</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>august</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>.</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>:</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bit</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>.</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>l</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>##y</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>/</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>b</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>##gc</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>##y</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>##z</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>##0</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>#</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>photography</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[SEP]</td>\n",
       "      <td>-100</td>\n",
       "      <td>ignore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tokens  ner_labels       ner_tags\n",
       "0         [CLS]        -100         ignore\n",
       "1             p           1  B-corporation\n",
       "2        ##xley        -100         ignore\n",
       "3          ##es        -100         ignore\n",
       "4           top           0              O\n",
       "5            50           0              O\n",
       "6   photography           0              O\n",
       "7       contest           0              O\n",
       "8      pictures           0              O\n",
       "9            of           0              O\n",
       "10       august           0              O\n",
       "11         2010           0              O\n",
       "12            .           0              O\n",
       "13            .        -100         ignore\n",
       "14            .        -100         ignore\n",
       "15         http           0              O\n",
       "16            :        -100         ignore\n",
       "17            /        -100         ignore\n",
       "18            /        -100         ignore\n",
       "19          bit        -100         ignore\n",
       "20            .        -100         ignore\n",
       "21            l        -100         ignore\n",
       "22          ##y        -100         ignore\n",
       "23            /        -100         ignore\n",
       "24            b        -100         ignore\n",
       "25         ##gc        -100         ignore\n",
       "26          ##y        -100         ignore\n",
       "27          ##z        -100         ignore\n",
       "28          ##0        -100         ignore\n",
       "29            #           0              O\n",
       "30  photography        -100         ignore\n",
       "31        [SEP]        -100         ignore"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2tag[-100]='ignore'\n",
    "exml=tokenized_train_dataset[2]\n",
    "\n",
    "pd.DataFrame({'tokens':tokenizer.convert_ids_to_tokens(exml[\"input_ids\"]), 'ner_labels':exml['labels'], 'ner_tags': [id2tag[label] for label in exml['labels']] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b77292c-686c-4291-b54f-85159504f78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5888494815191806"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base model\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(pd.Series(tokenized_train_dataset['input_ids']).explode(), pd.Series(tokenized_train_dataset['labels']).explode().astype(str))\n",
    "dummy_clf.score(pd.Series(tokenized_train_dataset['input_ids']).explode(), pd.Series(tokenized_train_dataset['labels']).explode().astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ade9d32-2a97-48ea-a80b-4a2fd3f17d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7197897448947134"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_values=pd.Series(tokenized_train_dataset['labels']).explode()\n",
    "exploded_values=pd.DataFrame(exploded_values,columns=['B'])\n",
    "\n",
    "most_frequent_elem_by_doc=pd.Series(tokenized_train_dataset['labels']).apply(lambda x:  max(set(x), key=x.count))\n",
    "most_frequent_elem_by_doc=pd.DataFrame(most_frequent_elem_by_doc,columns=list('A'))\n",
    "\n",
    "df_most_freq_token=exploded_values.merge(most_frequent_elem_by_doc, how='right', left_index=True, right_index=True)\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(pd.Series(tokenized_train_dataset['input_ids']).explode(), df_most_freq_token['A'])\n",
    "dummy_clf.score(pd.Series(tokenized_train_dataset['input_ids']).explode(), df_most_freq_token['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdf97396-0848-4461-9bad-59207772ba59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|██████████| 420M/420M [04:34<00:00, 1.60MB/s] \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "#Data Collator\n",
    "\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64fa2369-8706-492e-a485-8facfdffdc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\programdata\\anaconda3\\envs\\stance\\lib\\site-packages (from seqeval) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\programdata\\anaconda3\\envs\\stance\\lib\\site-packages (from seqeval) (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\envs\\stance\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\envs\\stance\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\envs\\stance\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.7.1)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16171 sha256=8dd458885c3b1f50629e46e74b5717c9d102acfaa8feec1e2c445277abb4bd54\n",
      "  Stored in directory: c:\\users\\pc\\appdata\\local\\pip\\cache\\wheels\\ad\\5c\\ba\\05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5a1216c-18c4-4508-8bb5-806b2e08ffad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corporation': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_seqeval = load_metric(\"seqeval\")\n",
    "example = wnut[\"train\"][2]\n",
    "\n",
    "labels = [label_list[i] for i in example[\"ner_tags\"]]\n",
    "metric_seqeval.compute(predictions=[labels], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17995cc1-c1a0-448f-a387-02fcfe4c6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric_seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "705512e9-d734-4da9-9f15-ff130022b553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\stance\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4403\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1380\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1020' max='1380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1020/1380 49:44 < 17:35, 0.34 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.857654</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.009268</td>\n",
       "      <td>0.005529</td>\n",
       "      <td>0.800222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.462477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.925612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.358537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.925612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.320890</td>\n",
       "      <td>0.315985</td>\n",
       "      <td>0.078777</td>\n",
       "      <td>0.126113</td>\n",
       "      <td>0.930999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.309467</td>\n",
       "      <td>0.475162</td>\n",
       "      <td>0.203892</td>\n",
       "      <td>0.285344</td>\n",
       "      <td>0.936343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264187</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.281742</td>\n",
       "      <td>0.345651</td>\n",
       "      <td>0.939421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.253361</td>\n",
       "      <td>0.556686</td>\n",
       "      <td>0.354958</td>\n",
       "      <td>0.433503</td>\n",
       "      <td>0.941943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.239884</td>\n",
       "      <td>0.508813</td>\n",
       "      <td>0.401297</td>\n",
       "      <td>0.448705</td>\n",
       "      <td>0.944765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.536100</td>\n",
       "      <td>0.246245</td>\n",
       "      <td>0.553163</td>\n",
       "      <td>0.380908</td>\n",
       "      <td>0.451153</td>\n",
       "      <td>0.945663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.536100</td>\n",
       "      <td>0.260673</td>\n",
       "      <td>0.528590</td>\n",
       "      <td>0.385542</td>\n",
       "      <td>0.445874</td>\n",
       "      <td>0.946689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.536100</td>\n",
       "      <td>0.233912</td>\n",
       "      <td>0.520263</td>\n",
       "      <td>0.440222</td>\n",
       "      <td>0.476908</td>\n",
       "      <td>0.947843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.536100</td>\n",
       "      <td>0.248108</td>\n",
       "      <td>0.547980</td>\n",
       "      <td>0.402224</td>\n",
       "      <td>0.463923</td>\n",
       "      <td>0.948100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.536100</td>\n",
       "      <td>0.250648</td>\n",
       "      <td>0.542819</td>\n",
       "      <td>0.381835</td>\n",
       "      <td>0.448313</td>\n",
       "      <td>0.947971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.536100</td>\n",
       "      <td>0.259070</td>\n",
       "      <td>0.566281</td>\n",
       "      <td>0.407785</td>\n",
       "      <td>0.474138</td>\n",
       "      <td>0.949596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.536100</td>\n",
       "      <td>0.272815</td>\n",
       "      <td>0.554981</td>\n",
       "      <td>0.397590</td>\n",
       "      <td>0.463283</td>\n",
       "      <td>0.949040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.536100</td>\n",
       "      <td>0.268697</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.400371</td>\n",
       "      <td>0.476033</td>\n",
       "      <td>0.949510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.276878</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.409639</td>\n",
       "      <td>0.489209</td>\n",
       "      <td>0.950024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./log_results\\checkpoint-60\n",
      "Configuration saved in ./log_results\\checkpoint-60\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-60\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-60\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-60\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "C:\\ProgramData\\Anaconda3\\envs\\stance\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\stance\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./log_results\\checkpoint-120\n",
      "Configuration saved in ./log_results\\checkpoint-120\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-120\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-120\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-120\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "C:\\ProgramData\\Anaconda3\\envs\\stance\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\stance\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./log_results\\checkpoint-180\n",
      "Configuration saved in ./log_results\\checkpoint-180\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-180\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-180\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-180\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "C:\\ProgramData\\Anaconda3\\envs\\stance\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./log_results\\checkpoint-240\n",
      "Configuration saved in ./log_results\\checkpoint-240\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-240\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-240\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-240\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "C:\\ProgramData\\Anaconda3\\envs\\stance\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./log_results\\checkpoint-300\n",
      "Configuration saved in ./log_results\\checkpoint-300\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-300\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-300\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-300\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "C:\\ProgramData\\Anaconda3\\envs\\stance\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./log_results\\checkpoint-360\n",
      "Configuration saved in ./log_results\\checkpoint-360\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-360\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-360\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-360\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "C:\\ProgramData\\Anaconda3\\envs\\stance\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./log_results\\checkpoint-420\n",
      "Configuration saved in ./log_results\\checkpoint-420\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-420\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-420\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-420\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./log_results\\checkpoint-480\n",
      "Configuration saved in ./log_results\\checkpoint-480\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-480\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-480\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-480\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./log_results\\checkpoint-540\n",
      "Configuration saved in ./log_results\\checkpoint-540\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-540\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-540\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-540\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./log_results\\checkpoint-600\n",
      "Configuration saved in ./log_results\\checkpoint-600\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-600\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-600\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-600\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./log_results\\checkpoint-660\n",
      "Configuration saved in ./log_results\\checkpoint-660\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-660\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-660\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-660\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./log_results\\checkpoint-720\n",
      "Configuration saved in ./log_results\\checkpoint-720\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-720\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-720\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-720\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./log_results\\checkpoint-780\n",
      "Configuration saved in ./log_results\\checkpoint-780\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-780\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-780\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-780\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./log_results\\checkpoint-840\n",
      "Configuration saved in ./log_results\\checkpoint-840\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-840\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-840\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-840\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./log_results\\checkpoint-900\n",
      "Configuration saved in ./log_results\\checkpoint-900\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-900\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-900\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-900\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./log_results\\checkpoint-960\n",
      "Configuration saved in ./log_results\\checkpoint-960\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-960\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-960\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-960\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./log_results\\checkpoint-1020\n",
      "Configuration saved in ./log_results\\checkpoint-1020\\config.json\n",
      "Model weights saved in ./log_results\\checkpoint-1020\\pytorch_model.bin\n",
      "tokenizer config file saved in ./log_results\\checkpoint-1020\\tokenizer_config.json\n",
      "Special tokens file saved in ./log_results\\checkpoint-1020\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./log_results\\checkpoint-660 (score: 0.2339123785495758).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1020, training_loss=0.3020708860135546, metrics={'train_runtime': 2986.1804, 'train_samples_per_second': 7.372, 'train_steps_per_second': 0.462, 'total_flos': 432526398214206.0, 'train_loss': 0.3020708860135546, 'epoch': 3.7})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./log_results',\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,   \n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500, \n",
    "    eval_steps=60,\n",
    "    save_steps=60,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_wnut[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 6)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62f69844-31fc-4559-91e5-5e5a677a5985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'corporation': {'precision': 0.2597402597402597,\n",
       "  'recall': 0.30303030303030304,\n",
       "  'f1': 0.2797202797202797,\n",
       "  'number': 66},\n",
       " 'creative-work': {'precision': 0.35714285714285715,\n",
       "  'recall': 0.176056338028169,\n",
       "  'f1': 0.23584905660377353,\n",
       "  'number': 142},\n",
       " 'group': {'precision': 0.45,\n",
       "  'recall': 0.10909090909090909,\n",
       "  'f1': 0.17560975609756097,\n",
       "  'number': 165},\n",
       " 'location': {'precision': 0.5176470588235295,\n",
       "  'recall': 0.5866666666666667,\n",
       "  'f1': 0.5499999999999999,\n",
       "  'number': 150},\n",
       " 'person': {'precision': 0.623015873015873,\n",
       "  'recall': 0.7319347319347319,\n",
       "  'f1': 0.6730975348338694,\n",
       "  'number': 429},\n",
       " 'product': {'precision': 0.19230769230769232,\n",
       "  'recall': 0.07874015748031496,\n",
       "  'f1': 0.111731843575419,\n",
       "  'number': 127},\n",
       " 'overall_precision': 0.52026286966046,\n",
       " 'overall_recall': 0.4402224281742354,\n",
       " 'overall_f1': 0.47690763052208834,\n",
       " 'overall_accuracy': 0.9478431875507674}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_wnut[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric_seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eec0b192-7b12-49c1-90e1-295cd2abd130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: ner_tags, id, tokens. If ner_tags, id, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1287\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 01:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2339123785495758,\n",
       " 'eval_precision': 0.52026286966046,\n",
       " 'eval_recall': 0.4402224281742354,\n",
       " 'eval_f1': 0.47690763052208834,\n",
       " 'eval_accuracy': 0.9478431875507674,\n",
       " 'eval_runtime': 68.067,\n",
       " 'eval_samples_per_second': 18.908,\n",
       " 'eval_steps_per_second': 0.309,\n",
       " 'epoch': 3.7}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fffafd9-f002-45db-a625-08a3d13749dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(text:str):\n",
    "    # convert our text to a  tokenized sequence\n",
    "    #inputs = tokenizer(text, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "    inputs = tokenizer(text, truncation=True, return_tensors=\"pt\")\n",
    "    # get outputs\n",
    "    outputs = model(**inputs)\n",
    "    # convert to probabilities with softmax\n",
    "    probs = outputs[0][0].softmax(1)\n",
    "    # get the tags with the highest probability\n",
    "    word_tags = [(tokenizer.decode(inputs['input_ids'][0][i].item()), id2tag[tagid.item()]) \n",
    "                  for i, tagid in enumerate (probs.argmax(axis=1))]\n",
    "\n",
    "    return pd.DataFrame(word_tags, columns=['word', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cbcf313-0ad4-4b84-ac8f-c4d334159c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word         tag\n",
      "0         [CLS]           O\n",
      "1   celebrities           O\n",
      "2           and           O\n",
      "3      tourists           O\n",
      "4          from           O\n",
      "5        united  B-location\n",
      "6        states  B-location\n",
      "7           are           O\n",
      "8      flooding           O\n",
      "9          into           O\n",
      "10       greece  B-location\n",
      "11            .           O\n",
      "12          but           O\n",
      "13            a           O\n",
      "14        harsh           O\n",
      "15       winter           O\n",
      "16          isn           O\n",
      "17            ’           O\n",
      "18            t           O\n",
      "19          far           O\n",
      "20          off           O\n",
      "21        [SEP]           O\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Celebrities and tourists from United States are \n",
    "flooding into Greece. But a harsh winter isn’t far off\"\"\"\n",
    "\n",
    "print(tag_sentence(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3530c53-6299-41c5-992f-5db599178173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         word        tag\n",
      "0       [CLS]          O\n",
      "1       apple  B-product\n",
      "2          un          O\n",
      "3        ##ve          O\n",
      "4       ##ils          O\n",
      "5         all          O\n",
      "6           -          O\n",
      "7         new          O\n",
      "8         mac  B-product\n",
      "9      ##book  I-product\n",
      "10        air  I-product\n",
      "11          ,          O\n",
      "12      super          O\n",
      "13  ##charged          O\n",
      "14         by          O\n",
      "15        the          O\n",
      "16        new          O\n",
      "17         m2  B-product\n",
      "18       chip          O\n",
      "19      [SEP]          O\n"
     ]
    }
   ],
   "source": [
    "text=\"\"\"Apple unveils all-new MacBook Air, \n",
    "supercharged by the new M2 chip\"\"\"\n",
    "\n",
    "print(tag_sentence(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a5fdb59-27b2-4f7b-9b92-a63f1d710635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word tag\n",
      "0    [CLS]   O\n",
      "1       bu   O\n",
      "2       ge   O\n",
      "3     ##zi   O\n",
      "4     ##ye   O\n",
      "5       ka   O\n",
      "6    ##dar   O\n",
      "7       bo   O\n",
      "8    ##lon   O\n",
      "9     ##ya   O\n",
      "10     ile   O\n",
      "11      il   O\n",
      "12   ##isk   O\n",
      "13   ##imi   O\n",
      "14     ##z   O\n",
      "15      bi   O\n",
      "16   ##raz   O\n",
      "17      tu   O\n",
      "18    ##ha   O\n",
      "19    ##ft   O\n",
      "20     ##ı   O\n",
      "21      ve   O\n",
      "22      bu   O\n",
      "23      no   O\n",
      "24    ##kt   O\n",
      "25   ##ada   O\n",
      "26    sank   O\n",
      "27     ##i   O\n",
      "28     ken   O\n",
      "29   ##dis   O\n",
      "30   ##ine   O\n",
      "31      bi   O\n",
      "32     ##r   O\n",
      "33      oz   O\n",
      "34    ##ur   O\n",
      "35      bo   O\n",
      "36    ##rc   O\n",
      "37    ##lu   O\n",
      "38    ##yu   O\n",
      "39     ##z   O\n",
      "40      gi   O\n",
      "41    ##bi   O\n",
      "42  hissed   O\n",
      "43    ##iy   O\n",
      "44    ##or   O\n",
      "45    ##uz   O\n",
      "46       .   O\n",
      "47      oz   O\n",
      "48    ##ur   O\n",
      "49     dil   O\n",
      "50   ##eri   O\n",
      "51     ##z   O\n",
      "52      bo   O\n",
      "53   ##lon   O\n",
      "54    ##ya   O\n",
      "55   [SEP]   O\n"
     ]
    }
   ],
   "source": [
    "text=\"\"\"FISH MEAL (UNFINISHED) (UNFIT FOR HUMAN CONSUMPTION) (SIP NO.13328/2021/DADF DTD 02.09.2021)\"\"\"\n",
    "text=\"\"\"Bu geziye kadar Bolonya ile ilişkimiz biraz tuhaftı ve bu noktada sanki kendisine bir özür borçluyuz gibi hissediyoruz. Özür dileriz Bolonya\"\"\"\n",
    "print(tag_sentence(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd3c4d37-54c8-4e3c-b372-63c78a4344b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -r log_results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f5e8ad-7668-4881-848d-cd4f5e72f61c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
