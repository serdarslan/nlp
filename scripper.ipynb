{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42e715f6-d687-4c1f-b481-fe298a51100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitter_scraper import get_tweets\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b29f9-9b65-4fcd-a667-8d72250aa24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "247bf95b-5027-4591-9e4f-dfdb61b27ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets run one iteration to understand how to implement this library\n",
    "tweets = get_tweets(\"#deneysel\", pages = 1)\n",
    "tweets_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de17c0e7-7f5d-4532-b2e2-eaca3aa31785",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Oops! Either \"%23deneysel\" does not exist or is private.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\twitter_scraper\\modules\\tweets.py\u001b[0m in \u001b[0;36mgen_tweets\u001b[1;34m(pages)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 html = HTML(\n\u001b[1;32m---> 37\u001b[1;33m                     \u001b[0mhtml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"items_html\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"bunk\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                 )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'items_html'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-4b5adcfac254>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Running the code for one keyword and extracting the relevant data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   _ = pd.DataFrame({'text' : [tweet['text']],\n\u001b[0;32m      4\u001b[0m                     \u001b[1;34m'isRetweet'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'isRetweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[1;34m'replies'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'replies'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\twitter_scraper\\modules\\tweets.py\u001b[0m in \u001b[0;36mget_tweets\u001b[1;34m(query, pages)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mpages\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgen_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\twitter_scraper\\modules\\tweets.py\u001b[0m in \u001b[0;36mgen_tweets\u001b[1;34m(pages)\u001b[0m\n\u001b[0;32m     38\u001b[0m                 )\n\u001b[0;32m     39\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m     41\u001b[0m                     \u001b[1;34mf'Oops! Either \"{query}\" does not exist or is private.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 )\n",
      "\u001b[1;31mValueError\u001b[0m: Oops! Either \"%23deneysel\" does not exist or is private."
     ]
    }
   ],
   "source": [
    "\n",
    "# Running the code for one keyword and extracting the relevant data\n",
    "for tweet in tweets:\n",
    "  _ = pd.DataFrame({'text' : [tweet['text']],\n",
    "                    'isRetweet' : tweet['isRetweet'],\n",
    "                    'replies' : tweet['replies'],\n",
    "                    'retweets' : tweet['retweets'],\n",
    "                    'likes' : tweet['likes']\n",
    "                    })\n",
    "  tweets_df = tweets_df.append(_, ignore_index = True)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8f4298b-d18d-496e-bc4f-25534f546e6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Oops! Either \"%23deneysels%C4%B1v%C4%B1\" does not exist or is private.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\twitter_scraper\\modules\\tweets.py\u001b[0m in \u001b[0;36mgen_tweets\u001b[1;34m(pages)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 html = HTML(\n\u001b[1;32m---> 37\u001b[1;33m                     \u001b[0mhtml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"items_html\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"bunk\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                 )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'items_html'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c581fbe13b1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Lets print the keys and values obtained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Keys:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\twitter_scraper\\modules\\tweets.py\u001b[0m in \u001b[0;36mget_tweets\u001b[1;34m(query, pages)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mpages\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgen_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\twitter\\lib\\site-packages\\twitter_scraper\\modules\\tweets.py\u001b[0m in \u001b[0;36mgen_tweets\u001b[1;34m(pages)\u001b[0m\n\u001b[0;32m     38\u001b[0m                 )\n\u001b[0;32m     39\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m     41\u001b[0m                     \u001b[1;34mf'Oops! Either \"{query}\" does not exist or is private.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 )\n",
      "\u001b[1;31mValueError\u001b[0m: Oops! Either \"%23deneysels%C4%B1v%C4%B1\" does not exist or is private."
     ]
    }
   ],
   "source": [
    "# List of hashtags that we're interested in\n",
    "keywords = ['machinelearning', 'ML', 'deeplearning', \n",
    "            '#artificialintelligence', '#NLP', 'computervision', 'AI', \n",
    "            'tensorflow', 'pytorch', \"sklearn\", \"pandas\", \"plotly\", \n",
    "            \"spacy\", \"fastai\", 'datascience', 'dataanalysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f45eff-235a-4d10-b6eb-5c7d5830ead9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
